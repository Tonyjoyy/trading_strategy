{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8WVeJGYOIGsN+4eDK15E0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tonyjoyy/trading_strategy/blob/main/ETF_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "kdm74ChuuDnD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import yfinance as yf\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def download_data(symbol, start_date, end_date):\n",
        "    return yf.download(symbol, start=start_date, end=end_date)\n",
        "\n",
        "def calculate_rsi(prices, window):\n",
        "    delta = prices.diff(1)\n",
        "    gain = delta.clip(lower=0).rolling(window=window).mean()\n",
        "    loss = -delta.clip(upper=0).rolling(window=window).mean()\n",
        "    rs = gain / loss.replace(0, np.finfo(float).eps)  # Avoid division by zero\n",
        "    return 100 - (100 / (1 + rs))\n",
        "\n",
        "def sanitize_feature_names(df):\n",
        "    df.columns = [re.sub(r'[^A-Za-z0-9_]+', '', str(col)) for col in df.columns]\n",
        "    return df\n",
        "\n",
        "\n",
        "def compute_features(data_etf, data_sp500):\n",
        "    # Reset index to flatten the multi-index structure\n",
        "    data_etf = data_etf.reset_index()\n",
        "    data_sp500 = data_sp500.reset_index()\n",
        "\n",
        "    # Use 'Close' instead of 'Adj Close' (check for column existence)\n",
        "    if 'Close' not in data_etf.columns or 'Close' not in data_sp500.columns:\n",
        "        raise KeyError(\"The 'Close' column is missing in the downloaded data.\")\n",
        "\n",
        "    # Extract relevant columns\n",
        "    df = data_etf[['Close']].rename(columns={\"Close\": \"Price\"}).copy()\n",
        "    df['sp500price'] = data_sp500['Close']\n",
        "\n",
        "    # Compute simple return features\n",
        "    for i in range(1, 6):\n",
        "        df[f'Return_{i}'] = df['Price'].pct_change(i)\n",
        "\n",
        "    # Compute RSI\n",
        "    df['RSI_6'] = calculate_rsi(df['Price'], 6)\n",
        "    df['RSI_12'] = calculate_rsi(df['Price'], 12)\n",
        "    df['RSI_24'] = calculate_rsi(df['Price'], 24)\n",
        "\n",
        "    # Compute moving averages\n",
        "    for ma in [20, 50, 100, 200]:\n",
        "        df[f'MA{ma}_Price'] = df['Price'].rolling(window=ma).mean() / df['Price']\n",
        "        df[f'MA{ma}_Bigger'] = (df['Price'].rolling(window=ma).mean() - df['Price']) / df['Price']\n",
        "\n",
        "    # Compute SP500 features\n",
        "    sp500_returns = data_sp500['Close'].pct_change()\n",
        "    df['SP500_20Day_Mean_Return'] = sp500_returns.rolling(window=20).mean()\n",
        "\n",
        "    # Compute MACD\n",
        "    ema_short = df['Price'].ewm(span=12, adjust=False).mean()\n",
        "    ema_long = df['Price'].ewm(span=26, adjust=False).mean()\n",
        "    df['MACD'] = ema_short - ema_long\n",
        "    df['Signal_Line'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
        "    df['MACD_Histogram'] = df['MACD'] - df['Signal_Line']\n",
        "\n",
        "    # Compute new factors: highest and lowest prices\n",
        "    df['High20_to_Price'] = df['Price'].rolling(window=20).max() / df['Price']\n",
        "    df['Low20_to_Price'] = df['Price'].rolling(window=20).min() / df['Price']\n",
        "    df['High5_to_Price'] = df['Price'].rolling(window=5).max() / df['Price']\n",
        "    df['Low5_to_Price'] = df['Price'].rolling(window=5).min() / df['Price']\n",
        "\n",
        "    # Sanitize feature names\n",
        "    df = sanitize_feature_names(df)\n",
        "\n",
        "\n",
        "    return df.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_date, end_date = \"2017-01-01\", \"2025-01-01\"\n",
        "etf_symbol, sp500_symbol = \"XLF\", \"^GSPC\"\n",
        "data_etf = download_data(etf_symbol, start_date, end_date)\n",
        "data_sp500 = download_data(sp500_symbol, start_date, end_date)\n",
        "data_etf = data_etf.reset_index()\n",
        "data_sp500 = data_sp500.reset_index()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYuaypdeuQ-q",
        "outputId": "123d7239-c764-4684-fd91-69f594df27f6"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_etf.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlN4qA4auUvr",
        "outputId": "ebfb64b6-d1e7-4168-9f13-7df6ea94a2c3"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Price        Date      Close       High        Low       Open    Volume\n",
            "Ticker                   XLF        XLF        XLF        XLF       XLF\n",
            "0      2017-01-03  20.167595  20.304848  19.953137  20.253378  71259900\n",
            "1      2017-01-04  20.330580  20.356314  20.167592  20.227639  45092200\n",
            "2      2017-01-05  20.124695  20.296262  19.935973  20.270526  62201100\n",
            "3      2017-01-06  20.193327  20.279109  20.090387  20.201904  38060800\n",
            "4      2017-01-09  20.056067  20.184742  20.013176  20.141850  34022400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_features = compute_features(data_etf, data_sp500)\n",
        "print(df_features.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEtKiWJqub0M",
        "outputId": "2ed0c8ec-a406-4e0c-feb8-a02e2a010aa3"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['PriceXLF', 'sp500price', 'Return_1', 'Return_2', 'Return_3',\n",
            "       'Return_4', 'Return_5', 'RSI_6', 'RSI_12', 'RSI_24', 'MA20_Price',\n",
            "       'MA20_Bigger', 'MA50_Price', 'MA50_Bigger', 'MA100_Price',\n",
            "       'MA100_Bigger', 'MA200_Price', 'MA200_Bigger',\n",
            "       'SP500_20Day_Mean_Return', 'MACD', 'Signal_Line', 'MACD_Histogram',\n",
            "       'High20_to_Price', 'Low20_to_Price', 'High5_to_Price', 'Low5_to_Price'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "\n",
        "def preprocess_data(df):\n",
        "    # Calculate target variable: future returns\n",
        "    future_return = df['PriceXLF'].pct_change(5).shift(-5)\n",
        "    df['Target'] = future_return\n",
        "\n",
        "    # Replace inf with NaN and drop\n",
        "    df = df.replace([np.inf, -np.inf], np.nan).dropna()\n",
        "\n",
        "    # Create lagged features\n",
        "    for lag in range(1, 6):\n",
        "        df[f'Lag_{lag}'] = df['Target'].shift(lag)\n",
        "\n",
        "    # Replace inf with NaN and drop again\n",
        "    df = df.replace([np.inf, -np.inf], np.nan).dropna()\n",
        "\n",
        "    # Define features and target variable\n",
        "    X = df.drop(columns=['Target', 'PriceXLF', 'sp500price'])\n",
        "    y = df['Target']\n",
        "\n",
        "    feature_columns = X.columns.tolist()  # Save the exact columns used\n",
        "\n",
        "    # Split and scale\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    return X_train_scaled, X_test_scaled, y_train, y_test, scaler, feature_columns\n",
        "\n",
        "def train_lightgbm(X_train, y_train, X_test, y_test):\n",
        "  # Define the model with hyperparameters\n",
        "  model = lgb.LGBMRegressor(\n",
        "    num_leaves=31,          # Reduce to prevent overfitting\n",
        "    max_depth=-1,           # Allow trees to grow as deep as needed\n",
        "    learning_rate=0.05,     # Keep the learning rate\n",
        "    n_estimators=100,       # Increase number of trees for better learning\n",
        "    min_child_weight=0.1,   # Decrease to allow more splits\n",
        "    min_child_samples=20,   # Minimum number of samples in a leaf\n",
        "    feature_fraction=0.8,   # Slightly reduce to use fewer features\n",
        "    bagging_fraction=0.8,   # Keep the same\n",
        "    bagging_freq=5,         # Keep the same\n",
        "    lambda_l1=0.1,          # Add L1 regularization\n",
        "    lambda_l2=0.1,          # Add L2 regularization\n",
        "    random_state=42         # Seed for reproducibility\n",
        "  )\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  # Make predictions\n",
        "  y_pred = model.predict(X_test)\n",
        "\n",
        "  # Evaluate the model\n",
        "  mse = mean_squared_error(y_test, y_pred)\n",
        "  r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "  print(f'Mean Squared Error: {mse}')\n",
        "  print(f'R^2 Score: {r2}')\n",
        "\n",
        "  return model, y_pred"
      ],
      "metadata": {
        "id": "OiWm3F1XxnHz"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled, X_test_scaled, y_train, y_test, scaler, feature_columns = preprocess_data(df_features)\n",
        "trained_model = train_lightgbm(X_train_scaled, y_train, X_test_scaled, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZo1YkIjcm7w",
        "outputId": "694093b2-f03f-42dc-b218-4aab9b0418ff"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000545 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 7395\n",
            "[LightGBM] [Info] Number of data points in the train set: 1442, number of used features: 29\n",
            "[LightGBM] [Info] Start training from score 0.002992\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
            "Mean Squared Error: 0.0003262386280608067\n",
            "R^2 Score: 0.7229463109268368\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Fetch latest data\n",
        "end_date = datetime.today().strftime('%Y-%m-%d')  # 2025-02-26\n",
        "start_date = (datetime.today() - timedelta(days=500)).strftime('%Y-%m-%d')  # Extended for lags and features\n",
        "data_etf = yf.download(\"XLF\", start=start_date, end=end_date).reset_index()\n",
        "data_sp500 = yf.download(\"^GSPC\", start=start_date, end=end_date).reset_index()\n",
        "\n",
        "# Compute features\n",
        "df_features_latest = compute_features(data_etf, data_sp500)\n",
        "\n",
        "# Add lagged features using historical 5-day returns\n",
        "df_latest = df_features_latest.copy()\n",
        "future_return = df_latest['PriceXLF'].pct_change(5).shift(-5)  # Historical returns\n",
        "df_latest['Target'] = future_return\n",
        "for lag in range(1, 6):\n",
        "    df_latest[f'Lag_{lag}'] = df_latest['Target'].shift(lag)\n",
        "df_latest = df_latest.replace([np.inf, -np.inf], np.nan).dropna()\n",
        "\n",
        "\n",
        "# Debugging: Check columns\n",
        "print(\"Training feature columns:\", df_features.columns.tolist())\n",
        "print(\"Latest feature columns:\", df_latest.columns.tolist())\n",
        "print(\"Requested feature columns:\", feature_columns)\n",
        "\n",
        "# Preprocess for prediction\n",
        "def preprocess_for_prediction(df, scaler, feature_columns):\n",
        "    latest_data = df.tail(1).copy()  # Most recent row with lags\n",
        "    X_latest = latest_data[feature_columns]\n",
        "    X_latest_scaled = scaler.transform(X_latest)\n",
        "    return X_latest_scaled\n",
        "\n",
        "X_latest_scaled = preprocess_for_prediction(df_latest, scaler, feature_columns)\n",
        "\n",
        "# Predict\n",
        "model = trained_model[0]\n",
        "predicted_return = model.predict(X_latest_scaled)[0]\n",
        "print(f\"Predicted 5-day return for XLF starting {end_date}: {predicted_return * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFEGnySzktBo",
        "outputId": "a3cb999b-212b-467a-8ae6-657ed27f77f1"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training feature columns: ['PriceXLF', 'sp500price', 'Return_1', 'Return_2', 'Return_3', 'Return_4', 'Return_5', 'RSI_6', 'RSI_12', 'RSI_24', 'MA20_Price', 'MA20_Bigger', 'MA50_Price', 'MA50_Bigger', 'MA100_Price', 'MA100_Bigger', 'MA200_Price', 'MA200_Bigger', 'SP500_20Day_Mean_Return', 'MACD', 'Signal_Line', 'MACD_Histogram', 'High20_to_Price', 'Low20_to_Price', 'High5_to_Price', 'Low5_to_Price', 'Target']\n",
            "Latest feature columns: ['PriceXLF', 'sp500price', 'Return_1', 'Return_2', 'Return_3', 'Return_4', 'Return_5', 'RSI_6', 'RSI_12', 'RSI_24', 'MA20_Price', 'MA20_Bigger', 'MA50_Price', 'MA50_Bigger', 'MA100_Price', 'MA100_Bigger', 'MA200_Price', 'MA200_Bigger', 'SP500_20Day_Mean_Return', 'MACD', 'Signal_Line', 'MACD_Histogram', 'High20_to_Price', 'Low20_to_Price', 'High5_to_Price', 'Low5_to_Price', 'Target', 'Lag_1', 'Lag_2', 'Lag_3', 'Lag_4', 'Lag_5']\n",
            "Requested feature columns: ['Return_1', 'Return_2', 'Return_3', 'Return_4', 'Return_5', 'RSI_6', 'RSI_12', 'RSI_24', 'MA20_Price', 'MA20_Bigger', 'MA50_Price', 'MA50_Bigger', 'MA100_Price', 'MA100_Bigger', 'MA200_Price', 'MA200_Bigger', 'SP500_20Day_Mean_Return', 'MACD', 'Signal_Line', 'MACD_Histogram', 'High20_to_Price', 'Low20_to_Price', 'High5_to_Price', 'Low5_to_Price', 'Lag_1', 'Lag_2', 'Lag_3', 'Lag_4', 'Lag_5']\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
            "Predicted 5-day return for XLF starting 2025-02-26: -2.41%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}